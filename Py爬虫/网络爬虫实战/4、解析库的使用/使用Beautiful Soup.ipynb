{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beautiful Soup 借助网页的结构和属性等特性来解析网页。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1、简介\n",
    "\n",
    "---\n",
    "&nbsp;&nbsp;Beautiful Soup 就是Python的一个HTML或XML解析库，可以用它来方便的从网页中提取数据。官方解释如下：\n",
    "\n",
    "---\n",
    "&nbsp;&nbsp;Beautiful Soup 提供一些简单的、Python 式的函数来处理导航、搜索、修改分析树等功能。它是一个工具箱，通过解析文档为用户提供需要抓取的数据，因为简单，所以不需要多少代码就可以写出一个完整的应用程序。  \n",
    "  \n",
    "&nbsp;&nbsp;Beautiful Soup 自动将输入文档转换为Unicode编码，输出文档转换为UTF-8编码。你不需要考虑编码方式，除非文档没有指定一个编码方式，这时你仅仅需要说明一下原始编码方式就可以了。  \n",
    "  \n",
    "&nbsp;&nbsp;Beautiful Soup 已成为和lxml、html6lib一样出色的Python解释器，为用户灵活地提供不同的解析策略或强劲的速度。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2、准备工作\n",
    "\n",
    "---\n",
    "&nbsp;&nbsp;安装 Beautiful Soup 和 lxml 。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3、解析器\n",
    "\n",
    "---\n",
    "&nbsp;&nbsp;Beautiful Soup 在解析时实际上依赖解析器，它除了支持Python标准库中的HTML解析器外，还支持一些第三方解析器（比如lxml）。下表列出了Beautiful Soup支持的解析器：\n",
    "\n",
    "---\n",
    "|解析器|使用方法|优势|劣势|\n",
    "|:---|:---|:---|:---|\n",
    "|Python标准库|BeautifulSoup(markup, \"html.parser\")|Python的内置标准库、执行速度适中、文档容错能力强|Python2.7.3及3.2.2之前的版本文档容错能力差|\n",
    "|lxml HTML解析器|BeautifulSoup(markup, \"lxml\")|速度快、文档容错能力强|需要安装C语言库|\n",
    "|lxml XML解析器|BeautifulSoup(markup, \"xml\")|速度快、唯一支持XML的解析器|需要安装C语言库|\n",
    "|html5lib|BeautifulSoup(markup, \"html5lib\")|最好的容错性、以浏览器的方式解析文档、生成HTML5格式的文档|速度慢、不依赖外部扩展|\n",
    "\n",
    "---\n",
    "&nbsp;&nbsp;由上表看出，lxml解析器有解析HTML和XML的功能，而且速度快，容错能力强，所以推荐使用。\n",
    "\n",
    "---\n",
    "&nbsp;&nbsp;如果使用lxml，那么在初始化Beautiful Soup时，可以把第二个参数改为lxml即可\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4、基本用法\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T13:38:42.154506Z",
     "start_time": "2019-04-20T13:38:42.115579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   The Dormouse's story\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p class=\"title\" name=\"dromouse\">\n",
      "   <b>\n",
      "    The Dormouse's story\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   Once upon a time there were little sisters; and their names were\n",
      "   <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "    <!-- Elsie -->\n",
      "   </a>\n",
      "   ,\n",
      "   <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">\n",
      "    Lacie\n",
      "   </a>\n",
      "   and\n",
      "   <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">\n",
      "    Tillie\n",
      "   </a>\n",
      "   ;\n",
      "and they lived at the bottom of a well.\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   ...\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "The Dormouse's story\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\" name=\"dromouse\"><b>The Dormouse's story</b></p>\n",
    "<p class=\"story\">Once upon a time there were little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\"><!-- Elsie --></a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.prettify())\n",
    "print(soup.title.string)\n",
    "\n",
    "# 结果如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;这里首先声明变量html，它是一个HTML字符串。但是需要注意的是，它并不是一个完整的HTML字符串，因为body和html节点都没有闭合。接着，我们将它当作第一个参数传给BeautifulSoup对象，该对象的第二个参数为解析器的类型（这里使用lxml），此时就完成了BeautifulSoup对象的初始化。然后将这个对象赋值给soup变量。  \n",
    "&nbsp;&nbsp;接下来，就可以调用soup的各个方法和属性解析这串HTML代码了。  \n",
    "&nbsp;&nbsp;首先，调用prettify()方法。这个方法可以把要解析的字符串以标准的缩进格式输出。这里需要注意的是，输出结果里面包含body和html节点，也就是说对于不标准的HTML字符串BeautifulSoup，可以自动更正格式。这一步不是由prettify()方法做的，而是在初始化BeautifulSoup时就完成了。  \n",
    "&nbsp;&nbsp;然后调用soup.title.string，这实际上是输出HTML中title节点的文本内容。所以，soup.title可以选出HTML中的title节点，再调用string属性就可以得到里面的文本了，所以我们可以通过简单调用几个属性完成文本提取。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5、节点选择器\n",
    "\n",
    "---\n",
    "&nbsp;&nbsp;直接调用节点的名称就可以选择节点元素，再调用string属性就可以得到节点内的文本了，这种选择方式速度非常快。如果单个节点结构层次非常清晰，可以选用这种方式来解析。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 选择元素\n",
    "\n",
    "---\n",
    "下面再用一个例子说明选择元素的方法：\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T13:51:48.078652Z",
     "start_time": "2019-04-20T13:51:48.072668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>The Dormouse's story</title>\n",
      "<class 'bs4.element.Tag'>\n",
      "The Dormouse's story\n",
      "<head><title>The Dormouse's story</title></head>\n",
      "<p class=\"title\" name=\"dromouse\"><b>The Dormouse's story</b></p>\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\" name=\"dromouse\"><b>The Dormouse's story</b></p>\n",
    "<p class=\"story\">Once upon a time there were little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\"><!-- Elsie --></a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.title)\n",
    "print(type(soup.title))\n",
    "print(soup.title.string)\n",
    "print(soup.head)\n",
    "print(soup.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;这里依然选用刚才的HTML代码，首先打印输出title节点的选择结果，输出结果正是title节点加里面的文字内容。接下来，输出它的类型，是bs4.element.Tag类型，这是BeautifulSoup中一个重要的数据结构。经过选择器选择后，选择结果都是这种Tag类型。Tag具有一些属性，比如string属性，调用该属性，可以得到节点的文本内容，所以接下来的输出结果正是节点的文本内容。  \n",
    "&nbsp;&nbsp;接下来，我们又尝试选择了head节点，结果也是节点加其内部的所有内容。最后，选择了p节点。不过这次情况比较特殊，我们发现结果是第一个p节点的内容，后面的几个p节点并没有选到。也就是说，当有多个节点，这种选择方式只会选择到第一个匹配的节点，其他的后面节点都会忽略。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 提取信息\n",
    "\n",
    "---\n",
    "上面演示了调用string属性来获取文本的值，那么如何获取节点属性的值呢？如何获取节点名呢？\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）获取名称\n",
    "\n",
    "---\n",
    "&nbsp;&nbsp;可以利用name属性获取节点的名称。这里还是以上面的文本为例，选取title节点，然后调用name属性就可以得到节点名称："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T14:13:34.659682Z",
     "start_time": "2019-04-20T14:13:34.655660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\n"
     ]
    }
   ],
   "source": [
    "print(soup.title.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "(2)获取属性\n",
    "\n",
    "---\n",
    "&nbsp;&nbsp;每个节点可能有多个属性，比如id和class等，选择这个节点元素后，可以调用attrs获取所有属性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T14:15:24.381586Z",
     "start_time": "2019-04-20T14:15:24.377597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class': ['title'], 'name': 'dromouse'}\n",
      "dromouse\n"
     ]
    }
   ],
   "source": [
    "print(soup.p.attrs)\n",
    "print(soup.p.attrs['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;可以看到，attrs的返回结果是字典形式，它把选择的节点的所有属性和属性值组合成一个字典。接下来，如果要获取name属性，就相当于从字典中获取某个键值，只需要用中括号加属性名就可以了。比如，要获取name属性，就可以通过 attrs['name'] 来得到。  \n",
    "&nbsp;&nbsp;其实这样有点烦琐，还有一种更简单的获取方法：可以不用写attrs，直接在节点元素后面加中括号，传入属性名就可以获取属性值了。样例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T14:19:47.168217Z",
     "start_time": "2019-04-20T14:19:47.163231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dromouse\n",
      "['title']\n"
     ]
    }
   ],
   "source": [
    "print(soup.p['name'])\n",
    "print(soup.p['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;这里需要注意的是，有的返回结果是字符串，有的返回结果是字符串组成的列表。比如，name属性的值是唯一的，返回的结果就是单个字符串。而对于class，一个节点元素可能有多个class，所以返回的是列表。在实际处理过程中，我们要注意判断类型。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）获取内容\n",
    "\n",
    "---\n",
    "&nbsp;&nbsp;可以利用string属性获取节点元素包含的文本内容，比如要获取第一个p节点的文本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T14:23:10.240470Z",
     "start_time": "2019-04-20T14:23:10.236479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dormouse's story\n"
     ]
    }
   ],
   "source": [
    "print(soup.p.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再次注意一下，这里选择到的p节点是第一个p节点，获取的文本也是第一个p节点里面的文本。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 嵌套选择\n",
    "\n",
    "---\n",
    "&nbsp;&nbsp;在上面的例子中，我们知道每一个返回结果都是bs4.element.Tag类型，它同样可以继续调用节点进行下一步的选择。比如，我们获取了head节点元素，我们可以继续调用head来选取其内部的head节点元素："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T14:27:15.071609Z",
     "start_time": "2019-04-20T14:27:15.064628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>The Dormouse's story</title>\n",
      "<class 'bs4.element.Tag'>\n",
      "The Dormouse's story\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.head.title)\n",
    "print(type(soup.head.title))\n",
    "print(soup.head.title.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;第一行结果是调用head之后再次调用title而选择的title节点元素。然后打印输出了它的类型，可以看到，它仍然是bs4.element.Tag类型。也就是说，我们在Tag类型的基础上再次选择得到的依然还是Tag类型，每次返回的结果都相同，所以这样就可以做嵌套选择了。  \n",
    "&nbsp;&nbsp;最后，输出它的string属性，也就是节点里的文本内容。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 关联选择\n",
    "\n",
    "---\n",
    "在做选择的时候，有时候不能做到一步就选到想要的节点元素，需要先选中某一个节点元素，然后以它为基准再选择它的子节点、父节点、兄弟节点等，这里就来介绍如何选择这些节点元素。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）子节点和子孙节点\n",
    "\n",
    "---\n",
    "选取节点元素之后，如果想要获取它的直接子节点，可以调用contents属性，示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T02:12:04.922316Z",
     "start_time": "2019-04-26T02:12:04.884415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n   Once upon a time there were little sisters; and their names were\\n   ', <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>Elsie</span>\n",
      "</a>, '\\n', <a class=\"sister id=\" href=\"http://example.com/lacie\" link2=\"\">Lacie</a>, '\\n   and \\n   ', <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>, '\\n    and they lived at the bottom of a well.\\n   ']\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "<head>\n",
    "<title>The Dormouse's story</title>\n",
    "</head>\n",
    " <body>\n",
    "  <p class=\"story\">\n",
    "   Once upon a time there were little sisters; and their names were\n",
    "   <a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">\n",
    "    <span>Elsie</span>\n",
    "   </a>\n",
    "   <a href=\"http://example.com/lacie\" class=\"sister id=\"link2>Lacie</a>\n",
    "   and \n",
    "   <a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>\n",
    "    and they lived at the bottom of a well.\n",
    "   </p>\n",
    "  <p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.p.contents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，返回的结果是列表形式。p节点里既包含文本，又包含节点，最后会将它们以列表的形式统一返回。  \n",
    "需要注意的是，列表中的每个元素都是p节点的直接子节点。比如第一个a节点联盟包含一层span节点，这就相当于子孙节点了，但是返回结果并没有单独把span节点选出来。所以说，contents属性得到的结果是直接子节点的列表。  \n",
    "同样，我们可以调用children属性得到相应的结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T02:12:07.879556Z",
     "start_time": "2019-04-26T02:12:07.873524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<list_iterator object at 0x0000010F37EA32B0>\n",
      "0 \n",
      "   Once upon a time there were little sisters; and their names were\n",
      "   \n",
      "1 <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>Elsie</span>\n",
      "</a>\n",
      "2 \n",
      "\n",
      "3 <a class=\"sister id=\" href=\"http://example.com/lacie\" link2=\"\">Lacie</a>\n",
      "4 \n",
      "   and \n",
      "   \n",
      "5 <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n",
      "6 \n",
      "    and they lived at the bottom of a well.\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.p.children)\n",
    "for i, child in enumerate(soup.p.children):\n",
    "    print(i, child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还是同样的HTML文本，这里调用了children属性来选择，返回的结果是生成器类型。接下来，我们用for循环输出相应的内容。  \n",
    "  \n",
    "如果要得到所有的子孙节点的话，可以调用descendants属性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T02:14:50.560471Z",
     "start_time": "2019-04-26T02:14:50.554510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Tag.descendants at 0x0000010F37F60CF0>\n",
      "0 \n",
      "   Once upon a time there were little sisters; and their names were\n",
      "   \n",
      "1 <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>Elsie</span>\n",
      "</a>\n",
      "2 \n",
      "\n",
      "3 <span>Elsie</span>\n",
      "4 Elsie\n",
      "5 \n",
      "\n",
      "6 \n",
      "\n",
      "7 <a class=\"sister id=\" href=\"http://example.com/lacie\" link2=\"\">Lacie</a>\n",
      "8 Lacie\n",
      "9 \n",
      "   and \n",
      "   \n",
      "10 <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n",
      "11 Tillie\n",
      "12 \n",
      "    and they lived at the bottom of a well.\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.p.descendants)\n",
    "for i, child in enumerate(soup.p.descendants):\n",
    "    print(i, child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此时返回结果还是生成器。遍历输出一下可以看到，这次的输出结果就包含了span节点。descendants会递归查询所有子节点，得到所有的子孙节点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "（）父节点和祖先节点\n",
    "\n",
    "---\n",
    "如果要获取某个节点元素的父节点，可以调用parent属性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T02:18:08.468747Z",
     "start_time": "2019-04-26T02:18:08.463737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"story\">\n",
      "   Once upon a time there were little sisters; and their names were\n",
      "   <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>Elsie</span>\n",
      "</a>\n",
      "</p>\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "<head>\n",
    "<title>The Dormouse's story</title>\n",
    "</head>\n",
    " <body>\n",
    "  <p class=\"story\">\n",
    "   Once upon a time there were little sisters; and their names were\n",
    "   <a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">\n",
    "    <span>Elsie</span>\n",
    "   </a>\n",
    "    </p>\n",
    "  <p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.a.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们选择的是第一个a节点的父节点元素。很明显，它的父节点是p节点，输出结果便是p节点及其内部的内容。  \n",
    "需要注意的是，这里输出的仅仅是a节点的直接父节点，而没有再向外寻找父节点的祖先节点。如果想获取所有的祖先节点，可以调用parents属性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T02:22:45.423067Z",
     "start_time": "2019-04-26T02:22:45.418110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "[(0, <p class=\"story\">\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "</a>\n",
      "</p>), (1, <body>\n",
      "<p class=\"story\">\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "</a>\n",
      "</p>\n",
      "</body>), (2, <html>\n",
      "<body>\n",
      "<p class=\"story\">\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "</a>\n",
      "</p>\n",
      "</body></html>), (3, <html>\n",
      "<body>\n",
      "<p class=\"story\">\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "</a>\n",
      "</p>\n",
      "</body></html>)]\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "  <p class=\"story\">\n",
    "  <a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">\n",
    "  </a>\n",
    "  </p>\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(type(soup.a.parents))\n",
    "print(list(enumerate(soup.a.parents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现，返回结果是生成器类型。这里用列表输出了它的索引和内容，而列表中的元素就是a节点的祖先节点。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）兄弟节点\n",
    "\n",
    "---\n",
    "获取同级节点："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T02:30:23.757417Z",
     "start_time": "2019-04-26T02:30:23.752388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Sibling \n",
      "  hello\n",
      "  \n",
      "Prew Sibling \n",
      "      once upon a time there were threelittle sisters; \n",
      "  \n",
      "Next Sibling [(0, '\\n'), (1, ' '), (2, ' '), (3, 'h'), (4, 'e'), (5, 'l'), (6, 'l'), (7, 'o'), (8, '\\n'), (9, ' '), (10, ' ')]\n",
      "Prew Sibling [(0, '\\n'), (1, ' '), (2, ' '), (3, ' '), (4, ' '), (5, ' '), (6, ' '), (7, 'o'), (8, 'n'), (9, 'c'), (10, 'e'), (11, ' '), (12, 'u'), (13, 'p'), (14, 'o'), (15, 'n'), (16, ' '), (17, 'a'), (18, ' '), (19, 't'), (20, 'i'), (21, 'm'), (22, 'e'), (23, ' '), (24, 't'), (25, 'h'), (26, 'e'), (27, 'r'), (28, 'e'), (29, ' '), (30, 'w'), (31, 'e'), (32, 'r'), (33, 'e'), (34, ' '), (35, 't'), (36, 'h'), (37, 'r'), (38, 'e'), (39, 'e'), (40, 'l'), (41, 'i'), (42, 't'), (43, 't'), (44, 'l'), (45, 'e'), (46, ' '), (47, 's'), (48, 'i'), (49, 's'), (50, 't'), (51, 'e'), (52, 'r'), (53, 's'), (54, ';'), (55, ' '), (56, '\\n'), (57, ' '), (58, ' ')]\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "  <p class=\"story\">\n",
    "      once upon a time there were threelittle sisters; \n",
    "  <a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">\n",
    "  <span>Elsie</span>\n",
    "  </a>\n",
    "  hello\n",
    "  <a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a>\n",
    "  and\n",
    "  <a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>\n",
    "  and they lived happy.\n",
    "  </p>\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print('Next Sibling', soup.a.next_sibling)\n",
    "print('Prew Sibling', soup.a.previous_sibling)\n",
    "print('Next Sibling', list(enumerate(soup.a.next_sibling)))\n",
    "print('Prew Sibling', list(enumerate(soup.a.previous_sibling)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，这里调用了4个属性，其中next_sibling和previous_sibling分别获取节点的下一个和上一个兄弟元素，next_siblings和previous_siblings则分别返回后面和前面的兄弟节点。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（4）提取信息\n",
    "\n",
    "---\n",
    "前面讲解了关联元素节点的选择方法，如果想要获取它们的一些信息，比如文本、属性等，也用同样的方法，示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T03:24:49.725141Z",
     "start_time": "2019-04-26T03:24:49.717208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Sibling:\n",
      "<class 'bs4.element.NavigableString'>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Parent:\n",
      "<class 'generator'>\n",
      "<p class=\"story\">\n",
      "      once upon a time there were threelittle sisters; \n",
      "  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link1\">Bob</a>\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link2\">Tillie</a>\n",
      "</p>\n",
      "['story']\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "  <p class=\"story\">\n",
    "      once upon a time there were threelittle sisters; \n",
    "  <a href=\"http://example.com/lacie\" class=\"sister\" id=\"link1\">Bob</a>\n",
    "  <a href=\"http://example.com/tillie\" class=\"sister\" id=\"link2\">Tillie</a>\n",
    "  </p>\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print('Next Sibling:')\n",
    "print(type(soup.a.next_sibling))\n",
    "print(soup.a.next_sibling)\n",
    "print(soup.a.next_sibling.string)\n",
    "print('Parent:')\n",
    "print(type(soup.a.parents))\n",
    "print(list(soup.a.parents)[0])\n",
    "print(list(soup.a.parents)[0].attrs['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果返回结果是单个节点，那么可以直接调用string、attrs等属性获得其文本和属性；如果返回结果是多个节点的生成器，则可以转为列表后取出某个元素，然后再调用string、attrs等属性获取对应节点的文本和属性。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6、方法选择器\n",
    "\n",
    "---\n",
    "前面写的选择方法都是通过属性来选择的，这种方法非常快，但是如果进行比较复杂的选择的话，它就比较烦琐，不够灵活了。  \n",
    "BeautifulSoup中例如find_all()和find()等，调用它们，然后传入相应的参数，就可以灵活查询了。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### + find_all()\n",
    "\n",
    "---\n",
    "查询所有符合条件的元素。给它传入一些属性或文本，就可以得到符合条件的元素，它的功能十分强大。  \n",
    "它的API如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_all(name, attrs, recursive, text, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1)name  \n",
    "\n",
    "---\n",
    "我们可以根据节点名来查询元素，示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T03:36:11.097802Z",
     "start_time": "2019-04-26T03:36:11.090781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ul class=\"list\" id=\"list-1\">\n",
      "<li class=\"element\">Foo</li>\n",
      "<li class=\"element\">Bar</li>\n",
      "<li class=\"element\">Jay</li>\n",
      "</ul>, <ul class=\"list list-small\" id=\"list-2\">\n",
      "<li class=\"element\">Foo</li>\n",
      "<li class=\"element\">Bar</li>\n",
      "</ul>]\n",
      "<class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "html = '''\n",
    "<div class=\"panel\">\n",
    "<div class=\"panel-heading\">\n",
    "<h4>Hello</h4>\n",
    "</div>\n",
    "<div class=\"panel-body\">\n",
    "<ul class=\"list\" id=\"list-1\">\n",
    "<li class=\"element\">Foo</li>\n",
    "<li class=\"element\">Bar</li>\n",
    "<li class=\"element\">Jay</li>\n",
    "</ul>\n",
    "<ul class=\"list list-small\" id=\"list-2\">\n",
    "<li class=\"element\">Foo</li>\n",
    "<li class=\"element\">Bar</li>\n",
    "</ul>\n",
    "</div>\n",
    "</div>\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.find_all(name='ul'))\n",
    "print(type(soup.find_all(name='ul')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;这里我们调用了fing_all()方法，传入name参数，其参数值为ul。也就是说，我们想要查询所有ul节点，返回结果是列表类型，长度为2，每个元素依然都是bs4.element.Tag类型。  \n",
    "&nbsp;因为都是Tag类型，所以依然可以进行嵌套查询。还是同样的文本，这里查询出所有的ul节点后，再继续查询其内部的li节点："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T04:06:08.932180Z",
     "start_time": "2019-04-26T04:06:08.926201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>, <li class=\"element\">Jay</li>]\n",
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>]\n"
     ]
    }
   ],
   "source": [
    "for ul in soup.find_all(name='ul'):\n",
    "    print(ul.find_all(name='li'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "返回结果是列表类型，列表中的每个元素依然还是Tag类型。  \n",
    "\n",
    "---\n",
    "接下来，就可以遍历每个li，获取它的文本了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T04:13:03.819292Z",
     "start_time": "2019-04-26T04:13:03.815303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>, <li class=\"element\">Jay</li>]\n",
      "Foo\n",
      "Bar\n",
      "Jay\n",
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>]\n",
      "Foo\n",
      "Bar\n"
     ]
    }
   ],
   "source": [
    "for ul in soup.find_all(name='ul'):\n",
    "    print(ul.find_all(name='li'))\n",
    "    for li in ul.find_all(name='li'):\n",
    "        print(li.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2)attrs\n",
    "\n",
    "---\n",
    "除了根据节点名查询，我们也可以传入一些属性来查询，示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T04:24:29.543277Z",
     "start_time": "2019-04-26T04:24:29.536296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ul class=\"list\" id=\"list-1\" name=\"elements\">\n",
      "<li class=\"element\">Foo</li>\n",
      "<li class=\"element\">Bar</li>\n",
      "<li class=\"element\">Jay</li>\n",
      "</ul>]\n",
      "[<ul class=\"list\" id=\"list-1\" name=\"elements\">\n",
      "<li class=\"element\">Foo</li>\n",
      "<li class=\"element\">Bar</li>\n",
      "<li class=\"element\">Jay</li>\n",
      "</ul>]\n"
     ]
    }
   ],
   "source": [
    "html = '''\n",
    "<div class=\"panel\">\n",
    "<div class=\"panel-heading\">\n",
    "<h4>Hello</h4>\n",
    "</div>\n",
    "<div class=\"panel-body\">\n",
    "<ul class=\"list\" id=\"list-1\" name=\"elements\">\n",
    "<li class=\"element\">Foo</li>\n",
    "<li class=\"element\">Bar</li>\n",
    "<li class=\"element\">Jay</li>\n",
    "</ul>\n",
    "<ul class=\"list list-small\" id=\"list-2\">\n",
    "<li class=\"element\">Foo</li>\n",
    "<li class=\"element\">Bar</li>\n",
    "</ul>\n",
    "</div>\n",
    "</div>\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.find_all(attrs={'id': 'list-1'}))\n",
    "print(soup.find_all(attrs={'name': 'elements'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;这里查询的时候传入的是attrs参数，参数的类型是字典类型。比如，要查询id为list-1的节点，可以传入attrs={'id': 'list-1'}的查询条件，得到的结果是列表形式，包含的内容就是符合id为list-1的所有节点。在上面的例子中，符合条件的元素个数是1，所以结果是长度为1的列表。  \n",
    "&nbsp;&nbsp;对于一些常用的属性，比如id和class等，我们可以不用attrs来传递。比如，要查询id为list-1的节点，可以直接传入id这个参数。还是上面的文本，我们换一种方式来查询："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T05:40:53.192304Z",
     "start_time": "2019-04-26T05:40:53.185279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ul class=\"list\" id=\"list-1\" name=\"elements\">\n",
      "<li class=\"element\">Foo</li>\n",
      "<li class=\"element\">Bar</li>\n",
      "<li class=\"element\">Jay</li>\n",
      "</ul>]\n",
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>, <li class=\"element\">Jay</li>, <li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.find_all(id= 'list-1'))\n",
    "print(soup.find_all(class_= 'element'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里直接传入id='list-1'，就可以查询id为list-1的节点元素。而对于class来说，由于class在Python里是一个关键字，所以后面需要加一个下划线，即class_='element，返回的结果依然还是Tag组成的列表。  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）text\n",
    "\n",
    "---\n",
    "text参数可用来匹配节点的文本，传入的形式可以是字符串，可以是正则表达式对象，示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T05:46:26.156725Z",
     "start_time": "2019-04-26T05:46:26.150740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello, this is a link', 'Hello, this is a link, too']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "html = '''\n",
    "<div class=\"panel\">\n",
    "<div class=\"panel-body\">\n",
    "<a>Hello, this is a link</a>\n",
    "<a>Hello, this is a link, too</a>\n",
    "</div>\n",
    "</div>\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.find_all(text=re.compile('link')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里有两个a节点，其内部包含文本信息。这里再find_all()方法中传入text参数，该参数为正则表达式对象，结果返回所有匹配正则表达式的节点文本组成的列表。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ find()\n",
    "\n",
    "---\n",
    "除了find_all()方法，还有find()方法，只不过后者返回的是单个元素，也就是第一个匹配的元素，而前者返回的是所有匹配的元素组成的列表。示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T05:51:28.429274Z",
     "start_time": "2019-04-26T05:51:28.422293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ul class=\"list\" id=\"list-1\">\n",
      "<li class=\"element\">Foo</li>\n",
      "<li class=\"element\">Bar</li>\n",
      "<li class=\"element\">Jay</li>\n",
      "</ul>\n",
      "<class 'bs4.element.Tag'>\n",
      "<ul class=\"list\" id=\"list-1\">\n",
      "<li class=\"element\">Foo</li>\n",
      "<li class=\"element\">Bar</li>\n",
      "<li class=\"element\">Jay</li>\n",
      "</ul>\n"
     ]
    }
   ],
   "source": [
    "html = '''\n",
    "<div class=\"panel\">\n",
    "<div class=\"panel-heading\">\n",
    "<h4>Hello</h4>\n",
    "</div>\n",
    "<div class=\"panel-body\">\n",
    "<ul class=\"list\" id=\"list-1\">\n",
    "<li class=\"element\">Foo</li>\n",
    "<li class=\"element\">Bar</li>\n",
    "<li class=\"element\">Jay</li>\n",
    "</ul>\n",
    "<ul class=\"list list-small\" id=\"list-2\">\n",
    "<li class=\"element\">Foo</li>\n",
    "<li class=\"element\">Bar</li>\n",
    "</ul>\n",
    "</div>\n",
    "</div>\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.find(name='ul'))\n",
    "print(type(soup.find(name='ul')))\n",
    "print(soup.find(class_='list'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里的返回结果不再是列表形式，而是第一个匹配的节点元素，类型依然是Tag类型。  \n",
    "另外，还有许多种查询方法，其用法与前面介绍的find_all()、find()方法完全相同，只不过查询的范围不同，这里简单说明一下。  \n",
    "\n",
    "---\n",
    "find_parents()和find_parent()：前者返回所有祖先节点，后者返回直接父节点。\n",
    "\n",
    "---\n",
    "find_next_siblings()和find_next_sibling()：前者返回后面的所有的兄弟节点，后者返回后面第一个兄弟节点。\n",
    "\n",
    "---\n",
    "find_previous_siblings()和find_previous_sibling()：前者返回前面所有的兄弟节点，后者返回前面第一个兄弟节点。\n",
    "\n",
    "---\n",
    "find_all_next()和find_next()：前者返回节点后所有符合条件的节点，后者返回第一个符合条件的节点。\n",
    "\n",
    "---\n",
    "find_all_previous()和find_previous()：前者返回节点前所有符合条件的节点，后者返回第一个符合条件的节点。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7、CSS选择器\n",
    "\n",
    "---\n",
    "BeautifulSoup还提供了另外一种选择器，那就是CSS选择器。如果对Web开发熟悉的话，那么对CSS选择器肯定不陌生。可以参考 http://www.w3school.com.cn/cssref/css_selectors.asp 了解。\n",
    "\n",
    "---\n",
    "使用CSS选择器时，只需要调用select()方法，传入相应的CSS选择器即可， 示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T06:01:42.032193Z",
     "start_time": "2019-04-26T06:01:42.024173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div class=\"panel-heading\">\n",
      "<h4>Hello</h4>\n",
      "</div>]\n",
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>, <li class=\"element\">Jay</li>, <li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>]\n",
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>]\n",
      "<class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "html = '''\n",
    "<div class=\"panel\">\n",
    "<div class=\"panel-heading\">\n",
    "<h4>Hello</h4>\n",
    "</div>\n",
    "<div class=\"panel-body\">\n",
    "<ul class=\"list\" id=\"list-1\">\n",
    "<li class=\"element\">Foo</li>\n",
    "<li class=\"element\">Bar</li>\n",
    "<li class=\"element\">Jay</li>\n",
    "</ul>\n",
    "<ul class=\"list list-small\" id=\"list-2\">\n",
    "<li class=\"element\">Foo</li>\n",
    "<li class=\"element\">Bar</li>\n",
    "</ul>\n",
    "</div>\n",
    "</div>\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.select('.panel .panel-heading'))\n",
    "print(soup.select('ul li'))\n",
    "print(soup.select('#list-2 .element'))\n",
    "print(type(soup.select('ul')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;这里我们用了3次CSS选择器，返回的结果均是符合CSS选择器的节点组成的列表。例如，select('ul li')则是选择所有ul节点下面的所有li节点，结果便是所有的li节点组成的列表。  \n",
    "&nbsp;&nbsp;最后一句打印输出了列表中元素的类型。可以看到，类型依然是Tag类型。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 嵌套选择\n",
    "\n",
    "---\n",
    "select()方法同样支持嵌套选择。例如，先选择所有ul节点，再遍历每个ul节点，选择其li节点，样例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T06:16:59.520306Z",
     "start_time": "2019-04-26T06:16:59.514280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>, <li class=\"element\">Jay</li>]\n",
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "for ul in soup.select('ul'):\n",
    "    print(ul.select('li'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里正常输出了所有ul节点下所有li节点组成的列表。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 获取属性\n",
    "\n",
    "---\n",
    "我们知道节点类型是Tag， 所以获取属性还可以用原来的方法。仍然是上面的HTML文本，这里尝试获取每个ul节点的id属性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T06:19:27.162385Z",
     "start_time": "2019-04-26T06:19:27.156403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list-1\n",
      "list-1\n",
      "list-2\n",
      "list-2\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "for ul in soup.select('ul'):\n",
    "    print(ul['id'])\n",
    "    print(ul.attrs['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，直接传入中括号和属性名，以及通过attrs属性获取属性值，都可以成功。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 获取文本\n",
    "\n",
    "---\n",
    "要获取文本，当然也可以用前面所讲的string属性。此外，还有一个方法，那就是get_text()，示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T06:24:31.629068Z",
     "start_time": "2019-04-26T06:24:31.623083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Text: Foo\n",
      "String: Foo\n",
      "Get Text: Bar\n",
      "String: Bar\n",
      "Get Text: Jay\n",
      "String: Jay\n",
      "Get Text: Foo\n",
      "String: Foo\n",
      "Get Text: Bar\n",
      "String: Bar\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "for li in soup.select('li'):\n",
    "    print('Get Text:', li.get_text())\n",
    "    print('String:', li.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，二者的效果完全一致。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
