{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T14:30:31.397807Z",
     "start_time": "2019-05-12T14:30:31.395230Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T14:27:42.121565Z",
     "start_time": "2019-05-12T14:26:53.104394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_shape: (60000, 28, 28)\n",
      "y_shape: (60000,)\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.2864 - acc: 0.9135\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1161 - acc: 0.9643\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.0797 - acc: 0.9751\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.0589 - acc: 0.9816\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0431 - acc: 0.9861\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0318 - acc: 0.9904\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0246 - acc: 0.9925\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0173 - acc: 0.9954\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0113 - acc: 0.9974\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.0079 - acc: 0.9985\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "\n",
      "test loss 0.06950825035025482\n",
      "accuracy 0.9806\n",
      "60000/60000 [==============================] - 2s 27us/step\n",
      "\n",
      "train loss 0.005162006788730893\n",
      "train accuracy 0.9993833333333333\n"
     ]
    }
   ],
   "source": [
    "# 载入数据\n",
    "(x_train,y_train), (x_test,y_test) = mnist.load_data()\n",
    "\n",
    "# (60000,28,28)\n",
    "print('x_shape:', x_train.shape)\n",
    "# (60000,)\n",
    "print('y_shape:', y_train.shape)\n",
    "\n",
    "# (60000,28,28) --> (60000, 784)\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)/255.0\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)/255.0\n",
    "\n",
    "# 换　one-hot　格式\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# 创建模型，输入 784 个神经元，输出 10 神经元\n",
    "model = Sequential([\n",
    "    Dense(units=200, input_dim=784,\n",
    "          bias_initializer='one', activation='tanh'),\n",
    "    Dense(units=100,\n",
    "          bias_initializer='one', activation='tanh'),\n",
    "    Dense(units=10, \n",
    "          bias_initializer='one', activation='softmax')\n",
    "])\n",
    "\n",
    "# 定义优化器\n",
    "sgd = SGD(lr=0.2)\n",
    "\n",
    "# 定义优化器，　loss function, 训练过程中\n",
    "model.compile(\n",
    "    optimizer = sgd,\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy'],\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10)\n",
    "\n",
    "#　评估模型\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('\\ntest loss', loss)\n",
    "print('accuracy', accuracy)\n",
    "\n",
    "\n",
    "loss, accuracy = model.evaluate(x_train, y_train)\n",
    "\n",
    "print('\\ntrain loss', loss)\n",
    "print('train accuracy', accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 上面过拟合\n",
    "\n",
    "在训练集上几乎没什么误差，但是在测试集上误差较大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 使用 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T14:31:27.373301Z",
     "start_time": "2019-05-12T14:30:34.442168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_shape: (60000, 28, 28)\n",
      "y_shape: (60000,)\n",
      "WARNING:tensorflow:From /home/sizheng/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.4529 - acc: 0.8628\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.2822 - acc: 0.9157\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.2433 - acc: 0.9281\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.2181 - acc: 0.9355\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1971 - acc: 0.9417\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.1839 - acc: 0.9458\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1762 - acc: 0.9477\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1681 - acc: 0.9508\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.1589 - acc: 0.9529\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1557 - acc: 0.9539\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "\n",
      "test loss 0.09781392503157257\n",
      "accuracy 0.9704\n",
      "60000/60000 [==============================] - 1s 23us/step\n",
      "\n",
      "train loss 0.07494104421365386\n",
      "train accuracy 0.97735\n"
     ]
    }
   ],
   "source": [
    "# 载入数据\n",
    "(x_train,y_train), (x_test,y_test) = mnist.load_data()\n",
    "\n",
    "# (60000,28,28)\n",
    "print('x_shape:', x_train.shape)\n",
    "# (60000,)\n",
    "print('y_shape:', y_train.shape)\n",
    "\n",
    "# (60000,28,28) --> (60000, 784)\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)/255.0\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)/255.0\n",
    "\n",
    "# 换　one-hot　格式\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# 创建模型，输入 784 个神经元，输出 10 神经元\n",
    "model = Sequential([\n",
    "    Dense(units=200, input_dim=784,\n",
    "          bias_initializer='one', activation='tanh'),\n",
    "    Dropout(0.4),\n",
    "    Dense(units=100,\n",
    "          bias_initializer='one', activation='tanh'),\n",
    "    Dropout(0.4),\n",
    "    Dense(units=10, \n",
    "          bias_initializer='one', activation='softmax')\n",
    "])\n",
    "\n",
    "# 定义优化器\n",
    "sgd = SGD(lr=0.2)\n",
    "\n",
    "# 定义优化器，　loss function, 训练过程中\n",
    "model.compile(\n",
    "    optimizer = sgd,\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy'],\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10)\n",
    "\n",
    "#　评估模型\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('\\ntest loss', loss)\n",
    "print('accuracy', accuracy)\n",
    "\n",
    "\n",
    "loss, accuracy = model.evaluate(x_train, y_train)\n",
    "\n",
    "print('\\ntrain loss', loss)\n",
    "print('train accuracy', accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
