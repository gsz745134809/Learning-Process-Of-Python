{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24 项目实战：智联求职系列\n",
    "24.1 第一篇：数据采集并保存到 MongoDB 数据库\n",
    "24.1.1 前言\n",
    "本次主题分两篇文章来介绍：\n",
    "• 一、数据采集\n",
    "• 二、数据分析\n",
    "第一篇先来介绍数据采集，即用 python 爬取网站数据。\n",
    "24.1.2 运行环境和 python 库\n",
    "先说下运行环境：\n",
    "• python3.5\n",
    "• windows 7， 64 位系统\n",
    "本次智联招聘的网站爬取，主要涉及以下一些 python 库：\n",
    "• requests\n",
    "• BeautifulSoup\n",
    "• multiprocessing\n",
    "• pymongo\n",
    "• itertools\n",
    "24.1.3 爬取的主要步骤\n",
    "• 根据关键字、城市、以及⻚面编号生成需要爬取的网⻚链接\n",
    "• 用 requests 获取相应的网⻚内容\n",
    "• 用 BeautifulSoup 解析，获取需要的关键信息\n",
    "• 将爬取的信息存入 MongoDB 数据库中，插入新记录或更新已有记录\n",
    "• 用 multiprocessing 启动多进程进行爬取，提高运行效率\n",
    "24.1.4 文件组成\n",
    "• 信息配置文件“zhilian_kw_config.py”\n",
    "• 爬虫主运行文件“zhilian_kw_spider.py”\n",
    "在配置文件中设置需要爬取的信息，然后运行主程序进行内容抓取。\n",
    "配置文件“zhilian_kw_config.py”的内容如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T14:24:32.227260Z",
     "start_time": "2019-04-09T14:24:32.223186Z"
    }
   },
   "outputs": [],
   "source": [
    "TOTAL_PAGE_NUMBER = 90  # PAGE_NUMBER:total number of pages,可进行修改\n",
    "\n",
    "KEYWORDS = ['大数据', 'python', '投资经理']  # 需爬取的关键字可以自己添加或修改\n",
    "\n",
    "# 爬取主要城市的记录\n",
    "ADDRESS = ['全国', '北京', '上海', '广州', '深圳',\n",
    "           '天津', '武汉', '西安', '成都', '大连', \n",
    "           '长春', '沈阳', '南京', '济南', '青岛', \n",
    "           '杭州', '苏州', '无锡', '宁波', '重庆', \n",
    "           '郑州', '长沙', '福州', '厦门', '哈尔滨',\n",
    "           '石家庄', '合肥', '惠州', '太原', '昆明',\n",
    "           '烟台', '佛山', '南昌', '贵阳', '南宁']\n",
    "\n",
    "MONGO_URI = 'localhost'\n",
    "MONGO_DB = 'zhilian'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "爬虫主运行文件“zhilian_kw_spider.py”的内容如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datatime import datatime\n",
    "from urllib.parse import urlencode\n",
    "from multiprocessing import Pool\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import pymongo\n",
    "from zhilian.zhilian_kw_config import *\n",
    "import time \n",
    "from itertools import product\n",
    "\n",
    "client = pymongo.MongoClient(MONGO_URI)\n",
    "db = client[MONGO_DB]\n",
    "\n",
    "def down\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
